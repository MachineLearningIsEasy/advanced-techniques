{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Twitter_decision.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"f70FQePGYCno","colab_type":"code","outputId":"b3af96af-ef9f-43a8-8113-f127652f0e70","executionInfo":{"status":"ok","timestamp":1568627579576,"user_tz":-180,"elapsed":4455,"user":{"displayName":"Денис Ермолов","photoUrl":"","userId":"01582614778675332761"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["!pip install pymorphy2"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n","Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n","Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vI0rSTxNfMXu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5b1089ee-7b7c-402b-82b7-96bccc59a33f","executionInfo":{"status":"ok","timestamp":1568627582447,"user_tz":-180,"elapsed":855,"user":{"displayName":"Денис Ермолов","photoUrl":"","userId":"01582614778675332761"}}},"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","import re\n","from nltk.stem import WordNetLemmatizer\n","import sklearn\n","import codecs\n","import csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, HashingVectorizer\n","from sklearn.decomposition import PCA\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import SGDClassifier, RidgeClassifier, Perceptron\n","from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n","from sklearn.svm import LinearSVC\n","import pymorphy2\n","import seaborn as sns\n","sns.set_style(\"darkgrid\")\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dRIUfW88fI6A","colab_type":"code","colab":{}},"source":["\n","#FUNCTIONS------------------------------------------------------------------------------------------------------\n","#---------------------------------------------------------------------------------------------------------------\n","def list_to_str(arr):\n","    str_ = ''\n","    for rec in arr:\n","        str_+=rec\n","    return str_\n","\n","def csv_to_list(arr):\n","    arr_list = []\n","    for row in arr:\n","        arr_list.append(list_to_str(row))\n","    return arr_list\n","\n","def value_smiles_in_str(arr,str):\n","    count = 0\n","    for smile in arr:\n","        count+=str.count(smile)\n","    return count\n","\n","\n","def mistakes(arr,y,y_pred):\n","    for i in range(len(arr)):\n","        if y.iloc[i]!=y_pred[i]:\n","            print('True: ', y.iloc[i],' Prediction: ', y_pred[i],'\\n')\n","            print(arr.iloc[i])\n","            \n","def df_preprocess_str(text):    \n","    reg = re.compile('[^а-яА-яa-zA-Z0-9 ]') #\n","    text = text.lower().replace(\"ё\", \"е\")\n","    text = text.replace(\"ъ\", \"ь\")\n","    text = text.replace(\"й\", \"и\")\n","    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'сайт', text)\n","    text = re.sub('@[^\\s]+', 'пользователь', text)\n","    text = reg.sub(' ', text)\n","    morph = pymorphy2.MorphAnalyzer()\n","    #lemmatizer = WordNetLemmatizer()\n","    text_ = []\n","    for word in text.split():\n","        text_.append(morph.parse(word)[0].normal_form)\n","    return text_\n","\n","def get_vectorizer(str_): #'TF-IDF' sublinear_tf=True, max_df=0.5, stop_words='english'\n","  \n","    if str_ == 'HASH':\n","        vectorizer = HashingVectorizer(stop_words='english', alternate_sign=False\n","  ) #n_features=None\n","  \n","    if str_ == 'FP':#Feature Presence\n","        vectorizer = CountVectorizer(ngram_range=ngram_range,\n","                                         min_df=min_df,\n","                                         max_df=max_df)  # binary=True,stop_words='english'\n","\n","    if str_ == 'TF-IDF':#Feature Presence    \n","        vectorizer = TfidfVectorizer(ngram_range=(1,2),sublinear_tf=True, max_df=0.5, stop_words='english') # ngram_range=(1,2),binary=True stop_words='english' ngram_range=ngram_range,min_df=min_df, max_df=max_df, sublinear_tf=True\n","    return vectorizer\n","\n","\n","\n","def preprocess(df_train, df_test, str_):\n","\n","# генерим матрицу TFIDF, методом главных компонент (PCA) редуцируем вектора до размерности 100\n","    all_df = pd.concat([df_train['text'],df_test['text']], axis = 0)\n","    vectorizer =  get_vectorizer(str_)\n","    vectorizer.fit(all_df)\n","    Mat_count_train = vectorizer.transform(df_train['text'])\n","    Mat_count_test = vectorizer.transform(df_test['text'])\n","    return Mat_count_train, Mat_count_test\n","  \n","def check_model(model,data_t, y_t, data_v, y_v):\n","    scores = cross_val_score(model, data_t, y_t, cv=3, scoring='accuracy')\n","    print(model,'\\n Cross-validate: ', scores)\n","    model.fit(data_t,y_t)\n","    y_p = model.predict(data_v)\n","    print(\"Accuracy on valid data: \", accuracy_score(y_p,y_v))\n","    return y_p\n","  \n","def check_data_tf_idf(data_t, y_t, data_v, y_v):\n","    #forest = RandomForestClassifier(n_estimators=50)\n","    #check_model(forest,data_t, y_t, data_v, y_v)\n","    \n","    '''\n","    sgd_cl = SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n","       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n","       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n","       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n","       power_t=0.5, random_state=None, shuffle=True, tol=None,\n","       validation_fraction=0.1, verbose=0, warm_start=False)\n","    check_model(sgd_cl,data_t, y_t, data_v, y_v)\n","    \n","    sgd_cl_el = SGDClassifier(alpha=.0001, max_iter=50, penalty=\"elasticnet\")\n","    check_model(sgd_cl_el,data_t, y_t, data_v, y_v)\n","    '''\n","    linSVC = LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n","     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n","     verbose=0)\n","    check_model(linSVC,data_t, y_t, data_v, y_v)\n","    \n","    m_NB = MultinomialNB(alpha=.01)\n","    check_model(m_NB,data_t, y_t, data_v, y_v)\n","    \n","    b_NB = BernoulliNB(alpha=.005)\n","    check_model(b_NB,data_t, y_t, data_v, y_v)\n","    \n","    c_NB = ComplementNB(alpha=.001)\n","    check_model(c_NB,data_t, y_t, data_v, y_v)\n","    \n","    \n","def check_data_hash(data_t, y_t, data_v, y_v):\n","    #forest = RandomForestClassifier(n_estimators=50)\n","    #check_model(forest,data_t, y_t, data_v, y_v)\n","    \n","    '''\n","    sgd_cl = SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n","       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n","       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n","       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n","       power_t=0.5, random_state=None, shuffle=True, tol=None,\n","       validation_fraction=0.1, verbose=0, warm_start=False)\n","    check_model(sgd_cl,data_t, y_t, data_v, y_v)\n","    \n","    sgd_cl_el = SGDClassifier(alpha=.0001, max_iter=50, penalty=\"elasticnet\")\n","    check_model(sgd_cl_el,data_t, y_t, data_v, y_v)\n","    \n","    linSVC = LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n","     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n","     verbose=0)\n","    check_model(linSVC,data_t, y_t, data_v, y_v)\n","    '''\n","    ridge = RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n","        max_iter=None, normalize=False, random_state=None, solver='sag',\n","        tol=0.01)\n","    check_model(ridge,data_t, y_t, data_v, y_v)\n","    \n","    per = Perceptron(max_iter=70, tol=1e-3)\n","    check_model(per,data_t, y_t, data_v, y_v)    \n","#---------------------------------------------------------------------------------------------------------------"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"87Chu_tOYxW2","colab_type":"code","outputId":"781d26b9-f21e-4544-8551-8b500e178cf2","executionInfo":{"status":"error","timestamp":1568631830183,"user_tz":-180,"elapsed":59826,"user":{"displayName":"Денис Ермолов","photoUrl":"","userId":"01582614778675332761"}},"colab":{"base_uri":"https://localhost:8080/","height":426}},"source":["#READ DATA------------------------------------------------------------------------------------------------------\n","#---------------------------------------------------------------------------------------------------------------\n","positive_recalls = csv_to_list(csv.reader(codecs.open('/content/drive/My Drive/Colab Notebooks/NLP/positive_recalls.csv', 'rU', 'utf-8', errors='ignore')))\n","negative_recalls = csv_to_list(csv.reader(codecs.open('/content/drive/My Drive/Colab Notebooks/NLP/negative_recalls.csv', 'rU', 'utf-8', errors='ignore')))\n","\n","columns =['id','tdate','tmane','ttype','trtw','trep','tfav','tstcount','tfol','tfrien','listcount']\n","positive_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/NLP/positive.csv',names=columns, header=None,sep=';')\n","negative_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/NLP/negative.csv',names=columns, header=None,sep=';')\n","\n","DF_positive = pd.concat((positive_df, pd.DataFrame(positive_recalls,columns= ['text'], index = positive_df.index)), axis = 1)\n","DF_negative = pd.concat((negative_df, pd.DataFrame(negative_recalls,columns= ['text'], index = negative_df.index)), axis = 1)\n","\n","DF_positive_ = DF_positive.sample(frac=1.0) # рандомизированный выбор по умолчанию\n","DF_negative_ = DF_negative.sample(frac=1.0)\n","\n","df = pd.concat((DF_positive_, DF_negative_),axis = 0).sample(frac = 1) # объединяем и перемешиваем\n","\n","y = df['ttype'].replace({-1:0, 1:1})\n","del(df['ttype'])\n","X_train, X_valid, y_train, y_valid = train_test_split(df, y, test_size=.15, random_state=42, stratify=y)\n","print(X_train.shape,y_train.shape, X_valid.shape, y_valid.shape)\n","#---------------------------------------------------------------------------------------------------------------\n","#DATA PREPROCESSING---------------------------------------------------------------------------------------------\n","#---------------------------------------------------------------------------------------------------------------\n","\n","X_train['text'] = X_train['text'].apply(df_preprocess_str)\n","X_valid['text'] = X_valid['text'].apply(df_preprocess_str)\n","\n","#---------------------------------------------------------------------------------------------------------------"],"execution_count":16,"outputs":[{"output_type":"stream","text":["(192808, 11) (192808,) (34026, 11) (34026,)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-a2cc57bc099f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#---------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_preprocess_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_preprocess_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-15-47ebdc096b34>\u001b[0m in \u001b[0;36mdf_preprocess_str\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'@[^\\s]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'пользователь'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmorph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymorphy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMorphAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m#lemmatizer = WordNetLemmatizer()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtext_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, result_type, units, probability_estimator_cls)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_dictionary_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopencorpora_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprobability_estimator_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mprobability_estimator_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummySingleTagProbabilityEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymorphy2/opencorpora_dict/wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading dictionaries from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format: %(format_version)s, revision: %(source_revision)s, updated: %(compiled_at)s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymorphy2/opencorpora_dict/storage.py\u001b[0m in \u001b[0;36mload_dict\u001b[0;34m(path, gramtab_format)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mstr_gramtab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_gramtab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgramtab_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mgramtab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr_gramtab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0msuffixes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'suffixes.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymorphy2/opencorpora_dict/storage.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mstr_gramtab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_gramtab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgramtab_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mgramtab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr_gramtab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0msuffixes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'suffixes.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymorphy2/tagset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# - grammemes are interned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mgrammemes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mgrammemes_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrammemes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_grammemes_are_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammemes_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"yBwwvvorfd7d","colab_type":"code","outputId":"e9548324-2e72-452b-f785-6f40fc78787b","executionInfo":{"status":"ok","timestamp":1568627347787,"user_tz":-180,"elapsed":48718,"user":{"displayName":"Денис Ермолов","photoUrl":"","userId":"01582614778675332761"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["#TF-IDF----------------------------------------------------------------------------\n","#----------------------------------------------------------------------------------\n","tf_idf_train, tf_idf_valid   = preprocess(X_train, X_valid,  str_ = 'TF-IDF')#'HASH'\n","print('OLD shapes: ', tf_idf_train.shape, tf_idf_valid.shape)\n","lsvc = LinearSVC(C=3.0, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, loss='squared_hinge', max_iter=1000,multi_class='ovr', penalty='l1', random_state=None, tol=0.001,verbose=0).fit(tf_idf_train, y_train) #C=1.0, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, loss='squared_hinge', max_iter=1000,multi_class='ovr', penalty='l1', random_state=None, tol=0.001,verbose=0\n","#C=0.25, penalty=\"l1\", dual=False\n","model = SelectFromModel(lsvc, prefit=True, max_features  = None) #threshold = 1e-5,\n","tf_idf_train_new = model.transform(tf_idf_train)\n","tf_idf_valid_new = model.transform(tf_idf_valid)\n","print('\\nNew shapes: ', tf_idf_train_new.shape, tf_idf_valid_new.shape)\n","check_data_tf_idf(tf_idf_train_new, y_train, tf_idf_valid_new, y_valid)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["OLD shapes:  (192808, 1309149) (34026, 1309149)\n","\n","New shapes:  (192808, 178576) (34026, 178576)\n","LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n","          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n","          verbose=0) \n"," Cross-validate:  [0.7596857  0.76391417 0.75923073]\n","Accuracy on valid data:  0.7529536236995239\n","MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True) \n"," Cross-validate:  [0.81330325 0.8134715  0.8104685 ]\n","Accuracy on valid data:  0.7375242461646976\n","BernoulliNB(alpha=0.005, binarize=0.0, class_prior=None, fit_prior=True) \n"," Cross-validate:  [0.81311654 0.81325367 0.80807232]\n","Accuracy on valid data:  0.7403162287662376\n","ComplementNB(alpha=0.001, class_prior=None, fit_prior=True, norm=False) \n"," Cross-validate:  [0.81219854 0.8112776  0.80883474]\n","Accuracy on valid data:  0.735760888732146\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EVcYEhZSfZSQ","colab_type":"code","outputId":"8cc37808-938e-4c08-920b-59c5d8eb26b4","executionInfo":{"status":"ok","timestamp":1568627382053,"user_tz":-180,"elapsed":8170,"user":{"displayName":"Денис Ермолов","photoUrl":"","userId":"01582614778675332761"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["#PREDICT on tf-idf data\n","y_1 = check_model(LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n","     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n","     verbose=0),tf_idf_train_new, y_train, tf_idf_valid_new, y_valid)\n","y_2 = check_model(BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True),tf_idf_train_new, y_train, tf_idf_valid_new, y_valid)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n","          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n","          verbose=0) \n"," Cross-validate:  [0.75973238 0.76386749 0.75915294]\n","Accuracy on valid data:  0.7529536236995239\n","BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) \n"," Cross-validate:  [0.79094445 0.79154802 0.78498187]\n","Accuracy on valid data:  0.7495738552871334\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C8lL3LmveN30","colab_type":"code","outputId":"995dea29-a558-4554-e432-795ae494bf6b","executionInfo":{"status":"ok","timestamp":1568627447720,"user_tz":-180,"elapsed":23739,"user":{"displayName":"Денис Ермолов","photoUrl":"","userId":"01582614778675332761"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["#HASH----------------------------------------------------------------------------\n","#----------------------------------------------------------------------------------\n","tf_idf_train, tf_idf_valid   = preprocess(X_train, X_valid,  str_ = 'HASH')#'HASH'\n","print('OLD shapes: ', tf_idf_train.shape, tf_idf_valid.shape)\n","lsvc = LinearSVC(C=2.0, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, loss='squared_hinge', max_iter=1000,multi_class='ovr', penalty='l1', random_state=None, tol=0.001,verbose=0).fit(tf_idf_train, y_train) #C=1.0, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, loss='squared_hinge', max_iter=1000,multi_class='ovr', penalty='l1', random_state=None, tol=0.001,verbose=0\n","#C=0.25, penalty=\"l1\", dual=False\n","model = SelectFromModel(lsvc, prefit=True, max_features  = None) #threshold = 1e-5,\n","tf_idf_train_new = model.transform(tf_idf_train)\n","tf_idf_valid_new = model.transform(tf_idf_valid)\n","print('\\nNew shapes: ', tf_idf_train_new.shape, tf_idf_valid_new.shape)\n","check_data_hash(tf_idf_train_new, y_train, tf_idf_valid_new, y_valid)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["OLD shapes:  (192808, 1048576) (34026, 1048576)\n","\n","New shapes:  (192808, 59728) (34026, 59728)\n","RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n","                max_iter=None, normalize=False, random_state=None, solver='sag',\n","                tol=0.01) \n"," Cross-validate:  [0.76016804 0.76049106 0.7573947 ]\n","Accuracy on valid data:  0.7471051548815612\n","Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n","           fit_intercept=True, max_iter=70, n_iter_no_change=5, n_jobs=None,\n","           penalty=None, random_state=0, shuffle=True, tol=0.001,\n","           validation_fraction=0.1, verbose=0, warm_start=False) \n"," Cross-validate:  [0.73880504 0.72185657 0.74012354]\n","Accuracy on valid data:  0.7102803738317757\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1vdPxFfIfA16","colab_type":"code","outputId":"e754ef4c-b248-4925-9524-6433dca99235","executionInfo":{"status":"ok","timestamp":1568627459144,"user_tz":-180,"elapsed":7562,"user":{"displayName":"Денис Ермолов","photoUrl":"","userId":"01582614778675332761"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["#PREDICT on HASH data\n","y_3 = check_model(RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n","        max_iter=None, normalize=False, random_state=None, solver='sag',\n","        tol=0.01),tf_idf_train_new, y_train, tf_idf_valid_new, y_valid)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n","                max_iter=None, normalize=False, random_state=None, solver='sag',\n","                tol=0.01) \n"," Cross-validate:  [0.7601836  0.76075557 0.75750362]\n","Accuracy on valid data:  0.7471933227531887\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lqhBes1VgbUO","colab_type":"code","colab":{}},"source":["y_total = [y_1[i]*y_2[i] ^ y_1[i]*y_3[i] ^ y_2[i]*y_3[i] for i in range(len(y_1))]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D0JbSTN2hmIq","colab_type":"code","outputId":"6c6f220a-1d5d-46ac-decc-4c847f593def","executionInfo":{"status":"ok","timestamp":1568627463400,"user_tz":-180,"elapsed":1345,"user":{"displayName":"Денис Ермолов","photoUrl":"","userId":"01582614778675332761"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["print('Accuracy: ', accuracy_score(y_valid,y_total))\n","print('Precision: ', precision_score(y_valid,y_total))\n","print('Recall: ', recall_score(y_valid,y_total))\n","print('F1: ', f1_score(y_valid,y_total))\n","print('Confusion matrix:\\n', confusion_matrix(y_valid, y_total))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Accuracy:  0.7583612531593488\n","Precision:  0.7477056657690828\n","Recall:  0.7893484945176075\n","F1:  0.7679629734153637\n","Confusion matrix:\n"," [[12198  4591]\n"," [ 3631 13606]]\n"],"name":"stdout"}]}]}